async fn apq() -> Result<(), BoxError> {
        let config = RedisConfig::from_url("redis://127.0.0.1:6379").unwrap();
        let client = RedisClient::new(config, None, None, None);
        let connection_task = client.connect();
        client.wait_for_connect().await.unwrap();

        let config = json!({
            "apq": {
                "router": {
                    "cache": {
                        "in_memory": {
                            "limit": 2
                        },
                        "redis": {
                            "urls": ["redis://127.0.0.1:6379"],
                            "ttl": "10s"
                        }
                    }
                }
            }
        });

        let router = apollo_router::TestHarness::builder()
            .with_subgraph_network_requests()
            .configuration_json(config.clone())
            .unwrap()
            .schema(include_str!("../fixtures/supergraph.graphql"))
            .build_router()
            .await
            .unwrap();

        let query_hash = "4c45433039407593557f8a982dafd316a66ec03f0e1ed5fa1b7ef8060d76e8ec";

        client
            .del::<String, _>(&format!("apq:{query_hash}"))
            .await
            .unwrap();

        let persisted = json!({
            "version" : 1,
            "sha256Hash" : query_hash
        });

        // an APQ should fail if we do not know about the hash
        // it should not set a value in Redis
        let request: router::Request = supergraph::Request::fake_builder()
            .extension("persistedQuery", persisted.clone())
            .method(Method::POST)
            .build()
            .unwrap()
            .try_into()
            .unwrap();

        let res = router
            .clone()
            .oneshot(request)
            .await
            .unwrap()
            .into_graphql_response_stream()
            .await
            .next()
            .await
            .unwrap()
            .unwrap();
        assert_eq!(
            res.errors.first().unwrap().message,
            "PersistedQueryNotFound"
        );
        let r: Option<String> = client.get(&format!("apq:{query_hash}")).await.unwrap();
        assert!(r.is_none());

        // Now we register the query
        // it should set a value in Redis
        let request: router::Request = supergraph::Request::fake_builder()
            .query(r#"{ topProducts { name name2:name } }"#)
            .extension("persistedQuery", persisted.clone())
            .method(Method::POST)
            .build()
            .unwrap()
            .try_into()
            .unwrap();

        let res = router
            .clone()
            .oneshot(request)
            .await
            .unwrap()
            .into_graphql_response_stream()
            .await
            .next()
            .await
            .unwrap()
            .unwrap();
        assert!(res.data.is_some());
        assert!(res.errors.is_empty());

        let s: Option<String> = client.get(&format!("apq:{query_hash}")).await.unwrap();
        insta::assert_display_snapshot!(s.unwrap());

        // we start a new router with the same config
        // it should have the same connection to Redis, but the in memory cache has been reset
        let router = apollo_router::TestHarness::builder()
            .with_subgraph_network_requests()
            .configuration_json(config.clone())
            .unwrap()
            .schema(include_str!("../fixtures/supergraph.graphql"))
            .build_router()
            .await
            .unwrap();

        // a request with only the hash should succeed because it is stored in Redis
        let request: router::Request = supergraph::Request::fake_builder()
            .extension("persistedQuery", persisted.clone())
            .method(Method::POST)
            .build()
            .unwrap()
            .try_into()
            .unwrap();

        let res = router
            .clone()
            .oneshot(request)
            .await
            .unwrap()
            .into_graphql_response_stream()
            .await
            .next()
            .await
            .unwrap()
            .unwrap();
        assert!(res.data.is_some());
        assert!(res.errors.is_empty());

        client.quit().await.unwrap();
        // calling quit ends the connection and event listener tasks
        let _ = connection_task.await;
        Ok(())
    }

fn arguments() {
        let schema1: &str = r#"
        type Query {
          a(i: Int): Int
          b(i: Int = 1): Int
          c(i: Int = 1, j: Int): Int
        }
        "#;

        let schema2: &str = r#"
        type Query {
            a(i: Int!): Int
            b(i: Int = 2): Int
            c(i: Int = 2, j: Int): Int
          }
        "#;

        let query = "query { a(i: 0) }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        let query = "query { b }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        let query = "query { b(i: 0)}";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        let query = "query { c(j: 0)}";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        let query = "query { c(i:0, j: 0)}";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));
    }

fn call(&mut self, req: QueryPlannerRequest) -> Self::Future {
        let QueryPlannerRequest {
            query: original_query,
            operation_name,
            context,
        } = req;

        let metadata = context
            .extensions()
            .lock()
            .get::<CacheKeyMetadata>()
            .cloned()
            .unwrap_or_default();
        let this = self.clone();
        let fut = async move {
            let mut doc = match context.extensions().lock().get::<ParsedDocument>().cloned() {
                None => return Err(QueryPlannerError::SpecError(SpecError::UnknownFileId)),
                Some(d) => d,
            };

            let api_schema = this.schema.api_schema();
            let api_schema_definitions = &api_schema.definitions;
            match add_defer_labels(api_schema_definitions, &doc.ast) {
                Err(e) => {
                    return Err(QueryPlannerError::SpecError(SpecError::TransformError(
                        e.to_string(),
                    )))
                }
                Ok(modified_query) => {
                    let executable_document = modified_query
                        .to_executable_validate(api_schema_definitions)
                        // Assume transformation creates a valid document: ignore conversion errors
                        .map_err(|e| SpecError::ValidationError(e.into()))?;
                    let hash = QueryHashVisitor::hash_query(
                        api_schema_definitions,
                        &api_schema.raw_sdl,
                        &executable_document,
                        operation_name.as_deref(),
                    )
                    .map_err(|e| SpecError::QueryHashing(e.to_string()))?;
                    doc = Arc::new(ParsedDocumentInner {
                        executable: Arc::new(executable_document),
                        ast: modified_query,
                        hash: Arc::new(QueryHash(hash)),
                    });
                    context
                        .extensions()
                        .lock()
                        .insert::<ParsedDocument>(doc.clone());
                }
            }

            let plan_options = PlanOptions {
                override_conditions: context
                    .get(LABELS_TO_OVERRIDE_KEY)
                    .unwrap_or_default()
                    .unwrap_or_default(),
            };

            let res = this
                .get(
                    QueryKey {
                        original_query,
                        filtered_query: doc.ast.to_string(),
                        operation_name: operation_name.to_owned(),
                        metadata,
                        plan_options,
                    },
                    doc,
                )
                .await;

            match res {
                Ok(query_planner_content) => Ok(QueryPlannerResponse::builder()
                    .content(query_planner_content)
                    .context(context)
                    .build()),
                Err(e) => {
                    match &e {
                        QueryPlannerError::PlanningErrors(pe) => {
                            context
                                .extensions()
                                .lock()
                                .insert(Arc::new(pe.usage_reporting.clone()));
                        }
                        QueryPlannerError::SpecError(e) => {
                            context.extensions().lock().insert(Arc::new(UsageReporting {
                                stats_report_key: e.get_error_key().to_string(),
                                referenced_fields_by_type: HashMap::new(),
                            }));
                        }
                        _ => (),
                    }
                    Err(e)
                }
            }
        };

        // Return the response as an immediate future
        Box::pin(fut)
    }



fn directive() {
        let schema1: &str = r#"
        schema {
          query: Query
        }
        directive @test on OBJECT | FIELD_DEFINITION | INTERFACE | SCALAR | ENUM
    
        type Query {
          me: User
          customer: User
        }
    
        type User {
          id: ID!
          name: String
        }
        "#;

        let schema2: &str = r#"
        schema {
            query: Query
        }
        directive @test on OBJECT | FIELD_DEFINITION | INTERFACE | SCALAR | ENUM
    
        type Query {
          me: User
          customer: User @test
        }
    
    
        type User {
          id: ID! @test
          name: String
        }
        "#;
        let query = "query { me { name } }";
        assert!(hash(schema1, query).equals(&hash(schema2, query)));

        let query = "query { me { id name } }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        let query = "query { customer { id } }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));
    }

fn doesnt_match(&self, other: &Self) -> bool {
            // This is intentional, we check to prevent BOTH hashes from being equal
            self.from_visitor != other.from_visitor && self.from_hash_query != other.from_hash_query
        }

async fn entity_cache() -> Result<(), BoxError> {
        let config = RedisConfig::from_url("redis://127.0.0.1:6379").unwrap();
        let client = RedisClient::new(config, None, None, None);
        let connection_task = client.connect();
        client.wait_for_connect().await.unwrap();

        let mut subgraphs = MockedSubgraphs::default();
        subgraphs.insert(
            "products",
            MockSubgraph::builder()
                .with_json(
                    serde_json::json! {{"query":"{topProducts{__typename upc name}}"}},
                    serde_json::json! {{"data": {
                            "topProducts": [{
                                "__typename": "Product",
                                "upc": "1",
                                "name": "chair"
                            },
                            {
                                "__typename": "Product",
                                "upc": "2",
                                "name": "table"
                            }]
                    }}},
                )
                .with_header(CACHE_CONTROL, HeaderValue::from_static("public"))
                .build(),
        );
        subgraphs.insert("reviews", MockSubgraph::builder().with_json(
            serde_json::json!{{
                "query": "query($representations:[_Any!]!){_entities(representations:$representations){...on Product{reviews{body}}}}",
                "variables": {
                    "representations": [
                        { "upc": "1", "__typename": "Product" },
                        { "upc": "2", "__typename": "Product" }
                    ],
                }
            }},
            serde_json::json! {{
                "data": {
                    "_entities":[
                        {
                            "reviews": [{
                                "body": "I can sit on it"
                            }]
                        },
                        {
                            "reviews": [{
                                "body": "I can sit on it"
                            },
                            {
                                "body": "I can eat on it"
                            }]
                        }
                    ]
                }
            }},
        ).with_header(CACHE_CONTROL, HeaderValue::from_static("public")).build());

        let supergraph = apollo_router::TestHarness::builder()
            .with_subgraph_network_requests()
            .configuration_json(json!({
                "preview_entity_cache": {
                    "redis": {
                        "urls": ["redis://127.0.0.1:6379"],
                        "ttl": "2s"
                    },
                    "enabled": false,
                    "subgraphs": {
                        "products": {
                            "enabled": true,
                            "ttl": "60s"
                        },
                        "reviews": {
                            "enabled": true,
                            "ttl": "10s"
                        }
                    }
                },
                "include_subgraph_errors": {
                    "all": true
                }
            }))
            .unwrap()
            .extra_plugin(subgraphs)
            .schema(include_str!("../fixtures/supergraph-auth.graphql"))
            .build_supergraph()
            .await
            .unwrap();

        let request = supergraph::Request::fake_builder()
            .query(r#"{ topProducts { name reviews { body } } }"#)
            .method(Method::POST)
            .build()
            .unwrap();

        let response = supergraph
            .oneshot(request)
            .await
            .unwrap()
            .next_response()
            .await
            .unwrap();
        insta::assert_json_snapshot!(response);

        let s:String = client
          .get("subgraph:products:Query:0df945dc1bc08f7fc02e8905b4c72aa9112f29bb7a214e4a38d199f0aa635b48:d9d84a3c7ffc27b0190a671212f3740e5b8478e84e23825830e97822e25cf05c")
          .await
          .unwrap();
        let v: Value = serde_json::from_str(&s).unwrap();
        insta::assert_json_snapshot!(v.as_object().unwrap().get("data").unwrap());

        let s: String = client.get("subgraph:reviews:Product:4911f7a9dbad8a47b8900d65547503a2f3c0359f65c0bc5652ad9b9843281f66:1de543dab57fde0f00247922ccc4f76d4c916ae26a89dd83cd1a62300d0cda20:d9d84a3c7ffc27b0190a671212f3740e5b8478e84e23825830e97822e25cf05c").await.unwrap();
        let v: Value = serde_json::from_str(&s).unwrap();
        insta::assert_json_snapshot!(v.as_object().unwrap().get("data").unwrap());

        // we abuse the query shape to return a response with a different but overlapping set of entities
        let mut subgraphs = MockedSubgraphs::default();
        subgraphs.insert(
            "products",
            MockSubgraph::builder()
                .with_json(
                    serde_json::json! {{"query":"{topProducts(first:2){__typename upc name}}"}},
                    serde_json::json! {{"data": {
                            "topProducts": [{
                                "__typename": "Product",
                                "upc": "1",
                                "name": "chair"
                            },
                            {
                                "__typename": "Product",
                                "upc": "3",
                                "name": "plate"
                            }]
                    }}},
                )
                .with_header(CACHE_CONTROL, HeaderValue::from_static("public"))
                .build(),
        );

        // even though the root operation returned 2 entities, we only need to get one entity from the subgraph here because
        // we already have it in cache
        subgraphs.insert("reviews", MockSubgraph::builder().with_json(
            serde_json::json!{{
                "query": "query($representations:[_Any!]!){_entities(representations:$representations){...on Product{reviews{body}}}}",
                "variables": {
                    "representations": [
                        { "upc": "3", "__typename": "Product" }
                    ],
                }
            }},
            serde_json::json! {{
                "data": {
                    "_entities":[
                        {
                            "reviews": [{
                                "body": "I can eat in it"
                            }]
                        }
                    ]
                }
            }},
        ).with_header(CACHE_CONTROL, HeaderValue::from_static("public")).build());

        let supergraph = apollo_router::TestHarness::builder()
            .with_subgraph_network_requests()
            .configuration_json(json!({
                "preview_entity_cache": {
                    "redis": {
                        "urls": ["redis://127.0.0.1:6379"],
                        "ttl": "2s"
                    },
                    "enabled": false,
                    "subgraphs": {
                        "products": {
                            "enabled": true,
                            "ttl": "60s"
                        },
                        "reviews": {
                            "enabled": true,
                            "ttl": "10s"
                        }
                    }
                },
                "include_subgraph_errors": {
                    "all": true
                }
            }))
            .unwrap()
            .extra_plugin(subgraphs)
            .schema(include_str!("../fixtures/supergraph-auth.graphql"))
            .build_supergraph()
            .await
            .unwrap();

        let request = supergraph::Request::fake_builder()
            .query(r#"{ topProducts(first: 2) { name reviews { body } } }"#)
            .method(Method::POST)
            .build()
            .unwrap();

        let response = supergraph
            .oneshot(request)
            .await
            .unwrap()
            .next_response()
            .await
            .unwrap();
        insta::assert_json_snapshot!(response);

        let s:String = client
        .get("subgraph:reviews:Product:d9a4cd73308dd13ca136390c10340823f94c335b9da198d2339c886c738abf0d:1de543dab57fde0f00247922ccc4f76d4c916ae26a89dd83cd1a62300d0cda20:d9d84a3c7ffc27b0190a671212f3740e5b8478e84e23825830e97822e25cf05c")
        .await
        .unwrap();
        let v: Value = serde_json::from_str(&s).unwrap();
        insta::assert_json_snapshot!(v.as_object().unwrap().get("data").unwrap());

        client.quit().await.unwrap();
        // calling quit ends the connection and event listener tasks
        let _ = connection_task.await;
        Ok(())
    }

async fn entity_cache_authorization() -> Result<(), BoxError> {
        let config = RedisConfig::from_url("redis://127.0.0.1:6379").unwrap();
        let client = RedisClient::new(config, None, None, None);
        let connection_task = client.connect();
        client.wait_for_connect().await.unwrap();

        let mut subgraphs = MockedSubgraphs::default();
        subgraphs.insert(
            "accounts",
            MockSubgraph::builder().with_json(
                serde_json::json!{{
                    "query": "query($representations:[_Any!]!){_entities(representations:$representations){...on User{username}}}",
                    "variables": {
                        "representations": [
                            { "__typename": "User", "id": "1" },
                            { "__typename": "User", "id": "2" }
                        ],
                    }
                }},
                serde_json::json! {{
                    "data": {
                        "_entities":[
                            {
                                "username": "ada"
                            },
                            {
                                "username": "charles"
                            }
                        ]
                    }
                }},
            ).with_json(
                serde_json::json! {{"query":"{me{id}}"}},
                serde_json::json! {{"data": {
                    "me": {
                        "id": "1"
                    }
                }}},
            ).with_header(CACHE_CONTROL, HeaderValue::from_static("public"))
            .build(),
        );
        subgraphs.insert(
            "products",
            MockSubgraph::builder()
                .with_json(
                    serde_json::json! {{"query":"{topProducts{__typename upc name}}"}},
                    serde_json::json! {{"data": {
                            "topProducts": [{
                                "__typename": "Product",
                                "upc": "1",
                                "name": "chair"
                            },
                            {
                                "__typename": "Product",
                                "upc": "2",
                                "name": "table"
                            }]
                    }}},
                )
                .with_header(CACHE_CONTROL, HeaderValue::from_static("public"))
                .build(),
        );
        subgraphs.insert(
            "reviews",
            MockSubgraph::builder().with_json(
                    serde_json::json!{{
                        "query": "query($representations:[_Any!]!){_entities(representations:$representations){...on Product{reviews{body}}}}",
                        "variables": {
                            "representations": [
                                { "upc": "1", "__typename": "Product" },
                                { "upc": "2", "__typename": "Product" }
                            ],
                        }
                    }},
                    serde_json::json! {{
                        "data": {
                            "_entities":[
                                {
                                    "reviews": [{
                                        "body": "I can sit on it"
                                    }]
                                },
                                {
                                    "reviews": [{
                                        "body": "I can sit on it"
                                    },
                                    {
                                        "body": "I can eat on it"
                                    }]
                                }
                            ]
                        }
                    }},
                ).with_json(
                    serde_json::json!{{
                        "query": "query($representations:[_Any!]!){_entities(representations:$representations){...on Product{reviews{body author{__typename id}}}}}",
                        "variables": {
                            "representations": [
                                { "upc": "1", "__typename": "Product" },
                                { "upc": "2", "__typename": "Product" }
                            ],
                        }
                    }},
                    serde_json::json! {{
                        "data": {
                            "_entities":[
                                {
                                    "reviews": [{
                                        "body": "I can sit on it",
                                        "author": {
                                            "__typename": "User",
                                            "id": "1"
                                        }
                                    }]
                                },
                                {
                                    "reviews": [{
                                        "body": "I can sit on it",
                                        "author": {
                                            "__typename": "User",
                                            "id": "1"
                                        }
                                    },
                                    {
                                        "body": "I can eat on it",
                                        "author": {
                                            "__typename": "User",
                                            "id": "2"
                                        }
                                    }]
                                }
                            ]
                        }
                    }},
                ).with_header(CACHE_CONTROL, HeaderValue::from_static("public"))
                .build(),
        );

        let supergraph = apollo_router::TestHarness::builder()
            .with_subgraph_network_requests()
            .configuration_json(json!({
                "preview_entity_cache": {
                    "redis": {
                        "urls": ["redis://127.0.0.1:6379"],
                        "ttl": "2s"
                    },
                    "enabled": false,
                    "subgraphs": {
                        "products": {
                            "enabled": true,
                            "ttl": "60s"
                        },
                        "reviews": {
                            "enabled": true,
                            "ttl": "10s"
                        }
                    }
                },
                "authorization": {
                    "preview_directives": {
                        "enabled": true
                    }
                },
                "include_subgraph_errors": {
                    "all": true
                }
            }))
            .unwrap()
            .extra_plugin(subgraphs)
            .schema(include_str!("../fixtures/supergraph-auth.graphql"))
            .build_supergraph()
            .await
            .unwrap();

        let context = Context::new();
        context
            .insert(
                "apollo_authorization::scopes::required",
                json! {["profile", "read:user", "read:name"]},
            )
            .unwrap();
        let request = supergraph::Request::fake_builder()
            .query(
                r#"{ me { id name } topProducts { name reviews { body author { username } } } }"#,
            )
            .context(context)
            .method(Method::POST)
            .build()
            .unwrap();

        let response = supergraph
            .clone()
            .oneshot(request)
            .await
            .unwrap()
            .next_response()
            .await
            .unwrap();
        insta::assert_json_snapshot!(response);

        let s:String = client
          .get("subgraph:products:Query:0df945dc1bc08f7fc02e8905b4c72aa9112f29bb7a214e4a38d199f0aa635b48:d9d84a3c7ffc27b0190a671212f3740e5b8478e84e23825830e97822e25cf05c")
          .await
          .unwrap();
        let v: Value = serde_json::from_str(&s).unwrap();
        assert_eq!(
            v.as_object().unwrap().get("data").unwrap(),
            &json! {{
                "topProducts": [{
                    "__typename": "Product",
                    "upc": "1",
                    "name": "chair"
                },
                {
                    "__typename": "Product",
                    "upc": "2",
                    "name": "table"
                }]
            }}
        );

        let s: String = client
        .get("subgraph:reviews:Product:4911f7a9dbad8a47b8900d65547503a2f3c0359f65c0bc5652ad9b9843281f66:1de543dab57fde0f00247922ccc4f76d4c916ae26a89dd83cd1a62300d0cda20:d9d84a3c7ffc27b0190a671212f3740e5b8478e84e23825830e97822e25cf05c")
        .await
        .unwrap();
        let v: Value = serde_json::from_str(&s).unwrap();
        assert_eq!(
            v.as_object().unwrap().get("data").unwrap(),
            &json! {{
                "reviews": [
                    {"body": "I can sit on it"}
                ]
            }}
        );

        let context = Context::new();
        context
            .insert(
                "apollo_authorization::scopes::required",
                json! {["profile", "read:user", "read:name"]},
            )
            .unwrap();
        context
            .insert(
                "apollo_authentication::JWT::claims",
                json! {{ "scope": "read:user read:name" }},
            )
            .unwrap();
        let request = supergraph::Request::fake_builder()
            .query(
                r#"{ me { id name } topProducts { name reviews { body author { username } } } }"#,
            )
            .context(context)
            .method(Method::POST)
            .build()
            .unwrap();

        let response = supergraph
            .clone()
            .oneshot(request)
            .await
            .unwrap()
            .next_response()
            .await
            .unwrap();
        insta::assert_json_snapshot!(response);

        let s:String = client
          .get("subgraph:reviews:Product:4911f7a9dbad8a47b8900d65547503a2f3c0359f65c0bc5652ad9b9843281f66:3b6ef3c8fd34c469d59f513942c5f4c8f91135e828712de2024e2cd4613c50ae:d9d84a3c7ffc27b0190a671212f3740e5b8478e84e23825830e97822e25cf05c")
          .await
          .unwrap();
        let v: Value = serde_json::from_str(&s).unwrap();
        assert_eq!(
            v.as_object().unwrap().get("data").unwrap(),
            &json! {{
                "reviews": [{
                    "body": "I can sit on it",
                    "author": {"__typename": "User", "id": "1"}
                }]
            }}
        );

        let context = Context::new();
        context
            .insert(
                "apollo_authorization::scopes::required",
                json! {["profile", "read:user", "read:name"]},
            )
            .unwrap();
        context
            .insert(
                "apollo_authentication::JWT::claims",
                json! {{ "scope": "read:user profile" }},
            )
            .unwrap();
        let request = supergraph::Request::fake_builder()
            .query(
                r#"{ me { id name } topProducts { name reviews { body author { username } } } }"#,
            )
            .context(context)
            .method(Method::POST)
            .build()
            .unwrap();

        let response = supergraph
            .clone()
            .oneshot(request)
            .await
            .unwrap()
            .next_response()
            .await
            .unwrap();
        insta::assert_json_snapshot!(response);

        client.quit().await.unwrap();
        // calling quit ends the connection and event listener tasks
        let _ = connection_task.await;
        Ok(())
    }

fn equals(&self, other: &Self) -> bool {
            self.from_visitor == other.from_visitor && self.from_hash_query == other.from_hash_query
        }

fn extract_query_information(
        schema: &Schema,
        document: &ExecutableDocument,
        operation_name: Option<&str>,
    ) -> Result<(Fragments, Vec<Operation>, DeferStats, Vec<u8>), SpecError> {
        let mut defer_stats = DeferStats {
            has_defer: false,
            has_unconditional_defer: false,
            conditional_defer_variable_names: IndexSet::new(),
        };
        let fragments = Fragments::from_hir(document, schema, &mut defer_stats)?;
        let operations = document
            .all_operations()
            .map(|operation| Operation::from_hir(operation, schema, &mut defer_stats, &fragments))
            .collect::<Result<Vec<_>, SpecError>>()?;

        let mut visitor = QueryHashVisitor::new(&schema.definitions, &schema.raw_sdl, document);
        traverse::document(&mut visitor, document, operation_name).map_err(|e| {
            SpecError::QueryHashing(format!("could not calculate the query hash: {e}"))
        })?;
        let hash = visitor.finish();

        Ok((fragments, operations, defer_stats, hash))
    }

fn field(
        &mut self,
        parent_type: &str,
        field_def: &ast::FieldDefinition,
        node: &executable::Field,
    ) -> Result<(), BoxError> {
        if !self.seen_introspection && (field_def.name == "__schema" || field_def.name == "__type")
        {
            self.seen_introspection = true;
            self.schema_str.hash(self);
        }

        self.hash_field(
            parent_type.to_string(),
            field_def.name.as_str().to_string(),
            field_def,
            &node.arguments,
        )?;

        traverse::field(self, field_def, node)
    }



async fn get(
        &self,
        mut key: QueryKey,
        mut doc: ParsedDocument,
    ) -> Result<QueryPlannerContent, QueryPlannerError> {
        let filter_res = if self.enable_authorization_directives {
            match AuthorizationPlugin::filter_query(&self.configuration, &key, &self.schema) {
                Err(QueryPlannerError::Unauthorized(unauthorized_paths)) => {
                    let response = graphql::Response::builder()
                        .data(Object::new())
                        .errors(
                            unauthorized_paths
                                .into_iter()
                                .map(|path| {
                                    graphql::Error::builder()
                                        .message("Unauthorized field or type")
                                        .path(path)
                                        .extension_code("UNAUTHORIZED_FIELD_OR_TYPE")
                                        .build()
                                })
                                .collect(),
                        )
                        .build();
                    return Ok(QueryPlannerContent::Response {
                        response: Box::new(response),
                    });
                }
                other => other?,
            }
        } else {
            None
        };

        let mut selections = self
            .parse_selections(
                key.original_query.clone(),
                key.operation_name.as_deref(),
                &doc,
            )
            .await?;

        if let Some((unauthorized_paths, new_doc)) = filter_res {
            key.filtered_query = new_doc.to_string();
            let executable_document = new_doc
                .to_executable_validate(&self.schema.api_schema().definitions)
                .map_err(|e| SpecError::ValidationError(e.into()))?;
            let hash = QueryHashVisitor::hash_query(
                &self.schema.definitions,
                &self.schema.raw_sdl,
                &executable_document,
                key.operation_name.as_deref(),
            )
            .map_err(|e| SpecError::QueryHashing(e.to_string()))?;
            doc = Arc::new(ParsedDocumentInner {
                executable: Arc::new(executable_document),
                ast: new_doc,
                hash: Arc::new(QueryHash(hash)),
            });
            selections.unauthorized.paths = unauthorized_paths;
        }

        if selections.contains_introspection() {
            // It can happen if you have a statically skipped query like { get @skip(if: true) { id name }} because it will be statically filtered with {}
            if selections
                .operations
                .first()
                .map(|op| op.selection_set.is_empty())
                .unwrap_or_default()
            {
                return Ok(QueryPlannerContent::Response {
                    response: Box::new(
                        graphql::Response::builder()
                            .data(Value::Object(Default::default()))
                            .build(),
                    ),
                });
            }
            // If we have only one operation containing only the root field `__typename`
            // (possibly aliased or repeated). (This does mean we fail to properly support
            // {"query": "query A {__typename} query B{somethingElse}", "operationName":"A"}.)
            if let Some(output_keys) = selections
                .operations
                .first()
                .and_then(|op| op.is_only_typenames_with_output_keys())
            {
                let operation_name = selections.operations[0].kind().to_string();
                let data: Value = Value::Object(Map::from_iter(
                    output_keys
                        .into_iter()
                        .map(|key| (key, Value::String(operation_name.clone().into()))),
                ));
                return Ok(QueryPlannerContent::Response {
                    response: Box::new(graphql::Response::builder().data(data).build()),
                });
            } else {
                return self.introspection(key.original_query).await;
            }
        }

        if key.filtered_query != key.original_query {
            let mut filtered = self
                .parse_selections(
                    key.filtered_query.clone(),
                    key.operation_name.as_deref(),
                    &doc,
                )
                .await?;
            filtered.is_original = false;
            selections.filtered_query = Some(Arc::new(filtered));
        }

        self.plan(
            key.original_query,
            key.filtered_query,
            key.operation_name,
            key.metadata,
            selections,
            key.plan_options,
            &doc,
        )
        .await
    }

fn hash(schema_str: &str, query: &str) -> HashComparator {
        let schema = Schema::parse(schema_str, "schema.graphql")
            .unwrap()
            .validate()
            .unwrap();
        let doc = Document::parse(query, "query.graphql").unwrap();

        let exec = doc
            .to_executable(&schema)
            .unwrap()
            .validate(&schema)
            .unwrap();
        let mut visitor = QueryHashVisitor::new(&schema, schema_str, &exec);
        traverse::document(&mut visitor, &exec, None).unwrap();

        (
            hex::encode(visitor.finish()),
            hex::encode(QueryHashVisitor::hash_query(&schema, schema_str, &exec, None).unwrap()),
        )
            .into()
    }

fn hash_query(
        schema: &'a schema::Schema,
        schema_str: &'a str,
        executable: &'a executable::ExecutableDocument,
        operation_name: Option<&str>,
    ) -> Result<Vec<u8>, BoxError> {
        let mut visitor = QueryHashVisitor::new(schema, schema_str, executable);
        traverse::document(&mut visitor, executable, operation_name)?;
        executable.to_string().hash(&mut visitor);
        Ok(visitor.finish())
    }

fn hash_subgraph_query(schema_str: &str, query: &str) -> String {
        let schema = Valid::assume_valid(Schema::parse(schema_str, "schema.graphql").unwrap());
        let doc = Document::parse(query, "query.graphql").unwrap();
        let exec = doc
            .to_executable(&schema)
            .unwrap()
            .validate(&schema)
            .unwrap();
        let mut visitor = QueryHashVisitor::new(&schema, schema_str, &exec);
        traverse::document(&mut visitor, &exec, None).unwrap();

        hex::encode(visitor.finish())
    }

fn hash_subqueries(
        &mut self,
        schemas: &HashMap<String, Arc<Valid<apollo_compiler::Schema>>>,
        supergraph_schema_hash: &str,
    ) {
        match self {
            PlanNode::Fetch(fetch_node) => {
                if let Some(schema) = schemas.get(&fetch_node.service_name) {
                    fetch_node.hash_subquery(schema, supergraph_schema_hash);
                }
            }

            PlanNode::Sequence { nodes } => {
                for node in nodes {
                    node.hash_subqueries(schemas, supergraph_schema_hash);
                }
            }
            PlanNode::Parallel { nodes } => {
                for node in nodes {
                    node.hash_subqueries(schemas, supergraph_schema_hash);
                }
            }
            PlanNode::Flatten(flatten) => flatten
                .node
                .hash_subqueries(schemas, supergraph_schema_hash),
            PlanNode::Defer { primary, deferred } => {
                if let Some(node) = primary.node.as_mut() {
                    node.hash_subqueries(schemas, supergraph_schema_hash);
                }
                for deferred_node in deferred {
                    if let Some(node) = deferred_node.node.take() {
                        let mut new_node = (*node).clone();
                        new_node.hash_subqueries(schemas, supergraph_schema_hash);
                        deferred_node.node = Some(Arc::new(new_node));
                    }
                }
            }
            PlanNode::Subscription { primary: _, rest } => {
                if let Some(node) = rest.as_mut() {
                    node.hash_subqueries(schemas, supergraph_schema_hash);
                }
            }
            PlanNode::Condition {
                condition: _,
                if_clause,
                else_clause,
            } => {
                if let Some(node) = if_clause.as_mut() {
                    node.hash_subqueries(schemas, supergraph_schema_hash);
                }
                if let Some(node) = else_clause.as_mut() {
                    node.hash_subqueries(schemas, supergraph_schema_hash);
                }
            }
        }
    }

fn interface() {
        let schema1: &str = r#"
        schema {
          query: Query
        }
        directive @test on OBJECT | FIELD_DEFINITION | INTERFACE | SCALAR | ENUM
    
        type Query {
          me: User
          customer: I
        }

        interface I {
            id: ID
        }
    
        type User implements I {
          id: ID!
          name: String
        }
        "#;

        let schema2: &str = r#"
        schema {
            query: Query
        }
        directive @test on OBJECT | FIELD_DEFINITION | INTERFACE | SCALAR | ENUM
    
        type Query {
          me: User
          customer: I
        }

        interface I @test {
            id: ID
        }
    
        type User implements I {
          id: ID!
          name: String
        }
        "#;

        let query = "query { me { id name } }";
        assert!(hash(schema1, query).equals(&hash(schema2, query)));

        let query = "query { customer { id } }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        let query = "query { customer { ... on User { name } } }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));
    }

fn join_type_key() {
        let schema1: &str = r#"
        schema
        @link(url: "https://specs.apollo.dev/link/v1.0")
        @link(url: "https://specs.apollo.dev/join/v0.3", for: EXECUTION) {
          query: Query
        }
        directive @test on OBJECT | FIELD_DEFINITION | INTERFACE | SCALAR | ENUM
        directive @join__type(graph: join__Graph!, key: join__FieldSet) repeatable on OBJECT | INTERFACE
        directive @join__graph(name: String!, url: String!) on ENUM_VALUE
        directive @link(url: String, as: String, for: link__Purpose, import: [link__Import]) repeatable on SCHEMA

        scalar join__FieldSet

        scalar link__Import

        enum link__Purpose {
            """
            `SECURITY` features provide metadata necessary to securely resolve fields.
            """
            SECURITY

            """
            `EXECUTION` features provide metadata necessary for operation execution.
            """
            EXECUTION
        }

        enum join__Graph {
            ACCOUNTS @join__graph(name: "accounts", url: "https://accounts.demo.starstuff.dev")
            INVENTORY @join__graph(name: "inventory", url: "https://inventory.demo.starstuff.dev")
            PRODUCTS @join__graph(name: "products", url: "https://products.demo.starstuff.dev")
            REVIEWS @join__graph(name: "reviews", url: "https://reviews.demo.starstuff.dev")
        }

        type Query {
          me: User
          customer: User
          itf: I
        }

        type User @join__type(graph: ACCOUNTS, key: "id") {
          id: ID!
          name: String
        }

        interface I @join__type(graph: ACCOUNTS, key: "id") {
            id: ID!
            name :String
        }

        union U = User
        "#;

        let schema2: &str = r#"
        schema
        @link(url: "https://specs.apollo.dev/link/v1.0")
        @link(url: "https://specs.apollo.dev/join/v0.3", for: EXECUTION) {
            query: Query
        }
        directive @test on OBJECT | FIELD_DEFINITION | INTERFACE | SCALAR | ENUM
        directive @join__type(graph: join__Graph!, key: join__FieldSet) repeatable on OBJECT | INTERFACE
        directive @join__graph(name: String!, url: String!) on ENUM_VALUE
        directive @link(url: String, as: String, for: link__Purpose, import: [link__Import]) repeatable on SCHEMA

        scalar join__FieldSet

        scalar link__Import

        enum link__Purpose {
            """
            `SECURITY` features provide metadata necessary to securely resolve fields.
            """
            SECURITY

            """
            `EXECUTION` features provide metadata necessary for operation execution.
            """
            EXECUTION
        }

        enum join__Graph {
            ACCOUNTS @join__graph(name: "accounts", url: "https://accounts.demo.starstuff.dev")
            INVENTORY @join__graph(name: "inventory", url: "https://inventory.demo.starstuff.dev")
            PRODUCTS @join__graph(name: "products", url: "https://products.demo.starstuff.dev")
            REVIEWS @join__graph(name: "reviews", url: "https://reviews.demo.starstuff.dev")
        }

        type Query {
          me: User
          customer: User @test
          itf: I
        }

        type User @join__type(graph: ACCOUNTS, key: "id") {
          id: ID! @test
          name: String
        }

        interface I @join__type(graph: ACCOUNTS, key: "id") {
            id: ID! @test
            name :String
        }
        "#;
        let query = "query { me { name } }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        let query = "query { itf { name } }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));
    }

fn me() {
        let schema1: &str = r#"
        schema {
          query: Query
        }
    
        type Query {
          me: User
          customer: User
        }
    
        type User {
          id: ID
          name: String
        }
        "#;

        let schema2: &str = r#"
        schema {
            query: Query
        }
    
        type Query {
          me: User
        }
    
    
        type User {
          id: ID!
          name: String
        }
        "#;
        let query = "query { me { name } }";
        assert!(hash(schema1, query).equals(&hash(schema2, query)));

        // id is nullable in 1, non nullable in 2
        let query = "query { me { id name } }";
        assert!(hash(schema1, query).doesnt_match(&hash(schema2, query)));

        // simple normalization
        let query = "query {  moi: me { name   } }";
        assert!(hash(schema1, query).equals(&hash(schema2, query)));

        assert!(hash(schema1, "query { me { id name } }")
            .doesnt_match(&hash(schema1, "query { me { name id } }")));
    }

fn parse_document(
        query: &str,
        operation_name: Option<&str>,
        schema: &Schema,
        configuration: &Configuration,
    ) -> Result<ParsedDocument, SpecError> {
        let parser = &mut apollo_compiler::Parser::new()
            .recursion_limit(configuration.limits.parser_max_recursion)
            .token_limit(configuration.limits.parser_max_tokens);
        let ast = match parser.parse_ast(query, "query.graphql") {
            Ok(ast) => ast,
            Err(errors) => {
                return Err(SpecError::ParseError(errors.into()));
            }
        };
        let api_schema = schema.api_schema();
        let api_schema_definitions = &api_schema.definitions;
        let executable_document = match ast.to_executable_validate(api_schema_definitions) {
            Ok(doc) => doc,
            Err(errors) => {
                return Err(SpecError::ValidationError(errors.into()));
            }
        };

        // Trace log recursion limit data
        let recursion_limit = parser.recursion_reached();
        tracing::trace!(?recursion_limit, "recursion limit data");

        let hash = QueryHashVisitor::hash_query(
            api_schema_definitions,
            &api_schema.raw_sdl,
            &executable_document,
            operation_name,
        )
        .map_err(|e| SpecError::QueryHashing(e.to_string()))?;

        Ok(Arc::new(ParsedDocumentInner {
            ast,
            executable: Arc::new(executable_document),
            hash: Arc::new(QueryHash(hash)),
        }))
    }

async fn plan(
        &self,
        original_query: String,
        filtered_query: String,
        operation: Option<String>,
        key: CacheKeyMetadata,
        selections: Query,
        plan_options: PlanOptions,
        doc: &ParsedDocument,
    ) -> Result<QueryPlannerContent, QueryPlannerError> {
        let planner_result = match self
            .planner
            .plan(filtered_query.clone(), operation.clone(), plan_options)
            .await
            .map_err(QueryPlannerError::RouterBridgeError)?
            .into_result()
        {
            Ok(mut plan) => {
                plan.data
                    .query_plan
                    .hash_subqueries(&self.subgraph_schemas, &self.schema.raw_sdl);
                plan.data
                    .query_plan
                    .extract_authorization_metadata(&self.schema.definitions, &key);
                plan
            }
            Err(err) => {
                let plan_errors: PlanErrors = err.into();
                return Err(QueryPlannerError::from(plan_errors));
            }
        };

        // the `statsReportKey` field should match the original query instead of the filtered query, to index them all under the same query
        let operation_signature = if matches!(
            self.configuration
                .experimental_apollo_metrics_generation_mode,
            ApolloMetricsGenerationMode::Legacy | ApolloMetricsGenerationMode::Both
        ) && original_query != filtered_query
        {
            Some(
                self.planner
                    .operation_signature(original_query.clone(), operation.clone())
                    .await
                    .map_err(QueryPlannerError::RouterBridgeError)?,
            )
        } else {
            None
        };

        match planner_result {
            PlanSuccess {
                data:
                    QueryPlanResult {
                        query_plan: QueryPlan { node: Some(node) },
                        formatted_query_plan,
                    },
                mut usage_reporting,
            } => {
                if let Some(sig) = operation_signature {
                    usage_reporting.stats_report_key = sig;
                }

                if matches!(
                    self.configuration
                        .experimental_apollo_metrics_generation_mode,
                    ApolloMetricsGenerationMode::New | ApolloMetricsGenerationMode::Both
                ) {
                    // If the query is filtered, we want to generate the signature using the original query and generate the
                    // reference using the filtered query. To do this, we need to re-parse the original query here.
                    let signature_doc = if original_query != filtered_query {
                        Query::parse_document(
                            &original_query,
                            operation.clone().as_deref(),
                            &self.schema,
                            &self.configuration,
                        )
                        .unwrap_or(doc.clone())
                    } else {
                        doc.clone()
                    };

                    let generated_usage_reporting = generate_usage_reporting(
                        &signature_doc.executable,
                        &doc.executable,
                        &operation,
                        &self.schema.definitions,
                    );

                    // Ignore comparison if the operation name is an empty string since there is a known issue where
                    // router behaviour is incorrect in that case, and it also generates incorrect usage reports.
                    // https://github.com/apollographql/router/issues/4837
                    let is_empty_operation_name = operation.map_or(false, |s| s.is_empty());
                    let is_in_both_metrics_mode = matches!(
                        self.configuration
                            .experimental_apollo_metrics_generation_mode,
                        ApolloMetricsGenerationMode::Both
                    );
                    if !is_empty_operation_name && is_in_both_metrics_mode {
                        let comparison_result = generated_usage_reporting.compare(&usage_reporting);

                        if matches!(
                            comparison_result,
                            UsageReportingComparisonResult::StatsReportKeyNotEqual
                                | UsageReportingComparisonResult::BothNotEqual
                        ) {
                            u64_counter!(
                                "apollo.router.operations.telemetry.studio.signature",
                                "The match status of the Apollo reporting signature generated by the JS implementation vs the Rust implementation",
                                1,
                                "generation.is_matched" = "false"
                            );
                            tracing::debug!(
                                "Different signatures generated between router and router-bridge:\n{}\n{}",
                                generated_usage_reporting.result.stats_report_key,
                                usage_reporting.stats_report_key,
                            );
                        } else {
                            u64_counter!(
                                "apollo.router.operations.telemetry.studio.signature",
                                "The match status of the Apollo reporting signature generated by the JS implementation vs the Rust implementation",
                                1,
                                "generation.is_matched" = "true"
                            );
                        }

                        if matches!(
                            comparison_result,
                            UsageReportingComparisonResult::ReferencedFieldsNotEqual
                                | UsageReportingComparisonResult::BothNotEqual
                        ) {
                            u64_counter!(
                                "apollo.router.operations.telemetry.studio.references",
                                "The match status of the Apollo reporting references generated by the JS implementation vs the Rust implementation",
                                1,
                                "generation.is_matched" = "false"
                            );
                            tracing::debug!(
                                "Different referenced fields generated between router and router-bridge:\n{:?}\n{:?}",
                                generated_usage_reporting.result.referenced_fields_by_type,
                                usage_reporting.referenced_fields_by_type,
                            );
                        } else {
                            u64_counter!(
                                "apollo.router.operations.telemetry.studio.references",
                                "The match status of the Apollo reporting references generated by the JS implementation vs the Rust implementation",
                                1,
                                "generation.is_matched" = "true"
                            );
                        }
                    } else if matches!(
                        self.configuration
                            .experimental_apollo_metrics_generation_mode,
                        ApolloMetricsGenerationMode::New
                    ) {
                        usage_reporting.stats_report_key =
                            generated_usage_reporting.result.stats_report_key;
                        usage_reporting.referenced_fields_by_type =
                            generated_usage_reporting.result.referenced_fields_by_type;
                    }
                }

                Ok(QueryPlannerContent::Plan {
                    plan: Arc::new(super::QueryPlan {
                        usage_reporting: Arc::new(usage_reporting),
                        root: node,
                        formatted_query_plan,
                        query: Arc::new(selections),
                    }),
                })
            }
            #[cfg_attr(feature = "failfast", allow(unused_variables))]
            PlanSuccess {
                data:
                    QueryPlanResult {
                        query_plan: QueryPlan { node: None },
                        ..
                    },
                mut usage_reporting,
            } => {
                failfast_debug!("empty query plan");
                if let Some(sig) = operation_signature {
                    usage_reporting.stats_report_key = sig;
                }

                Err(QueryPlannerError::EmptyPlan(usage_reporting))
            }
        }
    }

async fn query_planner() -> Result<(), BoxError> {
        // If this test fails and the cache key format changed you'll need to update the key here.
        // 1. Force this test to run locally by removing the cfg() line at the top of this file.
        // 2. run `docker compose up -d` and connect to the redis container by running `docker exec -ti <container_id> /bin/bash`.
        // 3. Run the `redis-cli` command from the shell and start the redis `monitor` command.
        // 4. Run this test and yank the updated cache key from the redis logs.
        let known_cache_key = "plan:v2.7.2:121b9859eba2d8fa6dde0a54b6e3781274cf69f7ffb0af912e92c01c6bfff6ca:3973e022e93220f9212c18d0d0c543ae7c309e46640da93a4a0314de999f5112:5c7a72fa35639949328548d77b56dba2e77d0dfa90c19b69978da119e996bb92";

        let config = RedisConfig::from_url("redis://127.0.0.1:6379").unwrap();
        let client = RedisClient::new(config, None, None, None);
        let connection_task = client.connect();
        client.wait_for_connect().await.unwrap();

        client.del::<String, _>(known_cache_key).await.unwrap();

        let supergraph = apollo_router::TestHarness::builder()
            .with_subgraph_network_requests()
            .configuration_json(json!({
                "supergraph": {
                    "query_planning": {
                        "cache": {
                            "in_memory": {
                                "limit": 2
                            },
                            "redis": {
                                "urls": ["redis://127.0.0.1:6379"],
                                "ttl": "10s"
                            }
                        }
                    }
                }
            }))
            .unwrap()
            .schema(include_str!("../fixtures/supergraph.graphql"))
            .build_supergraph()
            .await
            .unwrap();

        let request = supergraph::Request::fake_builder()
            .query(r#"{ topProducts { name name2:name } }"#)
            .method(Method::POST)
            .build()
            .unwrap();

        let _ = supergraph
            .oneshot(request)
            .await
            .unwrap()
            .next_response()
            .await;

        let s: String = match client.get(known_cache_key).await {
            Ok(s) => s,
            Err(e) => {
                println!("keys in Redis server:");
                let mut scan = client.scan("plan:*", None, Some(ScanType::String));
                while let Some(key) = scan.next().await {
                    let key = key.as_ref().unwrap().results();
                    println!("\t{key:?}");
                }
                panic!("key {known_cache_key} not found: {e}");
            }
        };
        let exp: i64 = client
            .custom_raw(cmd!("EXPIRETIME"), vec![known_cache_key.to_string()])
            .await
            .and_then(|frame| frame.try_into())
            .and_then(|value: RedisValue| value.convert())
            .unwrap();
        let query_plan_res: serde_json::Value = serde_json::from_str(&s).unwrap();
        // ignore the usage reporting field for which the order of elements in `referenced_fields_by_type` can change
        let query_plan = query_plan_res
            .as_object()
            .unwrap()
            .get("Ok")
            .unwrap()
            .get("Plan")
            .unwrap()
            .get("plan")
            .unwrap()
            .get("root");

        insta::assert_json_snapshot!(query_plan);

        // test expiration refresh
        tokio::time::sleep(std::time::Duration::from_secs(1)).await;
        let supergraph = apollo_router::TestHarness::builder()
            .with_subgraph_network_requests()
            .configuration_json(json!({
                "supergraph": {
                    "query_planning": {
                        "cache": {
                            "in_memory": {
                                "limit": 2
                            },
                            "redis": {
                                "urls": ["redis://127.0.0.1:6379"],
                                "ttl": "10s"
                            }
                        }
                    }
                }
            }))
            .unwrap()
            .schema(include_str!("../fixtures/supergraph.graphql"))
            .build_supergraph()
            .await
            .unwrap();

        let request = supergraph::Request::fake_builder()
            .query(r#"{ topProducts { name name2:name } }"#)
            .method(Method::POST)
            .build()
            .unwrap();
        let _ = supergraph
            .oneshot(request)
            .await
            .unwrap()
            .next_response()
            .await;
        let new_exp: i64 = client
            .custom_raw(cmd!("EXPIRETIME"), vec![known_cache_key.to_string()])
            .await
            .and_then(|frame| frame.try_into())
            .and_then(|value: RedisValue| value.convert())
            .unwrap();

        assert!(exp < new_exp);

        client.quit().await.unwrap();
        // calling quit ends the connection and event listener tasks
        let _ = connection_task.await;
        Ok(())
    }

